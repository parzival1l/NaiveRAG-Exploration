{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Pipeline - Linear Execution Format\n",
    "\n",
    "**üéì Practice Implementation**\n",
    "\n",
    "This is a simplified, hands-on practice execution of a RAG (Retrieval-Augmented Generation) pipeline using the most basic components possible. The focus is on understanding the core workflow, not production-grade code.\n",
    "\n",
    "## What's Implemented:\n",
    "\n",
    "- **Vector Database:** Qdrant\n",
    "- **Embedding Model:** nateraw/bge-large-en-v1.5 (via Replicate)\n",
    "- **LLM:** OpenAI through Replicate\n",
    "- **Dataset:** atitaarora/qdrant_doc\n",
    "- **Evaluation:** RAGAS\n",
    "\n",
    "## What's Intentionally Simplified:\n",
    "\n",
    "‚ö†Ô∏è This notebook **purposefully omits**:\n",
    "- ‚ùå Proper Python file structure & organization\n",
    "- ‚ùå Complex text parsers or NLP preprocessing\n",
    "- ‚ùå Advanced embedding models or fine-tuning\n",
    "- ‚ùå Production-ready error handling\n",
    "- ‚ùå Scalable database schemas\n",
    "- ‚ùå Comprehensive logging & monitoring\n",
    "\n",
    "**Goal:** Learn the RAG pipeline fundamentals by building it from scratch with minimal dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install -q qdrant-client\n",
    "%pip install -q langchain\n",
    "%pip install -q langchain-community\n",
    "%pip install -q replicate\n",
    "%pip install -q datasets\n",
    "%pip install -q ragas\n",
    "%pip install -q openai\n",
    "%pip install -q sentence-transformers\n",
    "%pip install -q numpy pandas tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import replicate\n",
    "from datasets import load_dataset\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Set API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"notebook_config.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded from config.json\n"
     ]
    }
   ],
   "source": [
    "replicate_api_token = config[\"api_keys\"][\"replicate_api_token\"]\n",
    "openai_api_key = config[\"api_keys\"][\"openai_api_key\"]\n",
    "qdrant_url = config[\"qdrant\"][\"url\"]\n",
    "qdrant_api_key = config[\"qdrant\"][\"api_key\"]\n",
    "\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = replicate_api_token\n",
    "print(\"‚úÖ Configuration loaded from config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 491 documents\n",
      "Dataset columns: ['text', 'source']\n"
     ]
    }
   ],
   "source": [
    "# Load the Qdrant documentation dataset\n",
    "dataset = load_dataset(\"atitaarora/qdrant_doc\", split=\"train\")\n",
    "print(f\"Loaded {len(dataset)} documents\")\n",
    "print(f\"Dataset columns: {dataset.column_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4.1: Replicate API test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Validating Replicate API Token...\n",
      "\n",
      "‚úÖ API call successful!\n",
      "Output type: <class 'list'>\n",
      "Output length: 3\n",
      "First 5 values: [0.001451187883503735, -0.0232482198625803, -0.01903114840388298, -0.03325076773762703, 0.012469109147787094]\n"
     ]
    }
   ],
   "source": [
    "# Validate Replicate API token\n",
    "print(\"üîç Validating Replicate API Token...\\n\")\n",
    "test_text = \"This is a test sentence for embedding generation.\"\n",
    "\n",
    "test_output = replicate.run(\n",
    "            \"beautyyuyanli/multilingual-e5-large:a06276a89f1a902d5fc225a9ca32b6e8e6292b7f3b136518878da97c458e2bad\",\n",
    "            input={\n",
    "                \"text\": test_text,\n",
    "                \"batch_size\": 32,\n",
    "                \"normalize_embeddings\": True}\n",
    "        )\n",
    "print(f\"‚úÖ API call successful!\")\n",
    "print(f\"Output type: {type(test_output)}\")\n",
    "print(f\"Output length: {len(test_output) if test_output else 'None'}\")\n",
    "if test_output:\n",
    "    print(f\"First 5 values: {test_output[1][:5]}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Output is None or empty!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Extract Text from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 491 documents\n",
      "Average document length: 7345 characters\n"
     ]
    }
   ],
   "source": [
    "# Extract documents from dataset\n",
    "documents = []\n",
    "for item in dataset:\n",
    "    if 'text' in item:\n",
    "        documents.append(item['text'])\n",
    "    elif 'content' in item:\n",
    "        documents.append(item['content'])\n",
    "    else:\n",
    "        # Try to get the first string field\n",
    "        for key, value in item.items():\n",
    "            if isinstance(value, str) and len(value) > 50:\n",
    "                documents.append(value)\n",
    "                break\n",
    "\n",
    "print(f\"Extracted {len(documents)} documents\")\n",
    "print(f\"Average document length: {np.mean([len(doc) for doc in documents]):.0f} characters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Split Documents into Chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 4877 chunks from 491 documents\n",
      "Average chunk length: 840 characters\n",
      "\n",
      "Example chunk:\n",
      "ogo/voiceflow.svg\n",
      "\n",
      "  -  /img/customers-logo/bosch-\n"
     ]
    }
   ],
   "source": [
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# Split documents\n",
    "chunks = []\n",
    "for doc in documents:\n",
    "    splits = text_splitter.split_text(doc)\n",
    "    chunks.extend(splits)\n",
    "\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks from {len(documents)} documents\")\n",
    "print(f\"Average chunk length: {np.mean([len(chunk) for chunk in chunks]):.0f} characters\")\n",
    "print(f\"\\nExample chunk:\")\n",
    "print(chunks[0][200:250])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Create Embedding Function Using Replicate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embedding function defined with proper unwrapping\n"
     ]
    }
   ],
   "source": [
    "def get_embeddings_replicate(texts):\n",
    "    \"\"\"\n",
    "    Get embeddings for a list of texts using Replicate's BGE model\n",
    "    Returns a flat list of embedding vectors (no nesting)\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "\n",
    "    for text in tqdm(texts, desc=\"Generating embeddings\"):\n",
    "        try:\n",
    "            output = replicate.run(\n",
    "                # \"nateraw/bge-large-en-v1.5:9cf9f015a9cb9c61d1a2610659cdac4a4ca222f2d3707a68517b18c198a9add1\", - this is a better model by it's coldstart is not working as expected.\n",
    "                \"beautyyuyanli/multilingual-e5-large:a06276a89f1a902d5fc225a9ca32b6e8e6292b7f3b136518878da97c458e2bad\",\n",
    "                input={\n",
    "                    \"text\": text,\n",
    "                    \"batch_size\": 32,\n",
    "                    \"normalize_embeddings\": True\n",
    "                }\n",
    "            )\n",
    "            # The API returns a nested structure, so we need to access the right index\n",
    "            if isinstance(output, list) and len(output) > 1:\n",
    "                # The embedding is at index 1 based on your debug output\n",
    "                embedding = output[1]\n",
    "            elif isinstance(output, list) and len(output) == 1:\n",
    "                # Fallback: if only one element, use it\n",
    "                embedding = output[0]\n",
    "            else:\n",
    "                # Direct assignment if already correct format\n",
    "                embedding = output\n",
    "\n",
    "            # Ensure it's a flat list of floats\n",
    "            if isinstance(embedding, list) and len(embedding) > 0:\n",
    "                if isinstance(embedding[0], list):\n",
    "                    # Still nested, unwrap once more\n",
    "                    embedding = embedding[0]\n",
    "\n",
    "            embeddings.append(embedding)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting embedding: {e}\")\n",
    "            # Use zero vector as fallback (1024 dimensions for this model)\n",
    "            embeddings.append([0.0] * 1024)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "print(\"‚úÖ Embedding function defined with proper unwrapping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Debug: Check Query Embedding Format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of result: <class 'list'>\n",
      "Length: 1\n",
      "Type of first element: <class 'list'>\n",
      "First element is a list with length: 1024\n",
      "First 5 values: [0.001451187883503735, -0.0232482198625803, -0.01903114840388298, -0.03325076773762703, 0.012469109147787094]\n",
      "‚úÖ Correctly formatted - single list of floats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check what format the query embedding has\n",
    "test_query = \"test query\"\n",
    "test_embedding = get_embeddings_replicate([test_query])\n",
    "\n",
    "print(f\"Type of result: {type(test_embedding)}\")\n",
    "print(f\"Length: {len(test_embedding)}\")\n",
    "print(f\"Type of first element: {type(test_embedding[0])}\")\n",
    "\n",
    "# Check if it's nested\n",
    "if test_embedding[0] is not None:\n",
    "    if isinstance(test_embedding[0], list):\n",
    "        print(f\"First element is a list with length: {len(test_embedding[0])}\")\n",
    "        print(f\"First 5 values: {test_embedding[0][:5]}\")\n",
    "\n",
    "        # Check if it's double-nested\n",
    "        if len(test_embedding[0]) > 0 and isinstance(test_embedding[0][0], list):\n",
    "            print(\"‚ö†Ô∏è  ISSUE: Double-nested list detected!\")\n",
    "            print(f\"Actual embedding is at: test_embedding[0][0]\")\n",
    "        else:\n",
    "            print(\"‚úÖ Correctly formatted - single list of floats\")\n",
    "    else:\n",
    "        print(f\"First element type: {type(test_embedding[0])}\")\n",
    "else:\n",
    "    print(\"‚ùå First element is None!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 25 chunks for embeddings...\n",
      "This may take a few minutes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:13<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated 25 embeddings\n",
      "Embedding dimension: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# For demo purposes, let's use a subset of chunks\n",
    "# Remove this limit for production use\n",
    "sample_size = min(25, len(chunks))  # Adjust based on your needs\n",
    "chunks_sample = chunks[:sample_size]\n",
    "\n",
    "print(f\"Processing {len(chunks_sample)} chunks for embeddings...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "# Generate embeddings\n",
    "chunk_embeddings = get_embeddings_replicate(chunks_sample)\n",
    "\n",
    "print(f\"\\nGenerated {len(chunk_embeddings)} embeddings\")\n",
    "print(f\"Embedding dimension: {len(chunk_embeddings[0])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Debug: Check Embeddings for all are returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embeddings: 25\n",
      "First embedding type: <class 'list'>\n",
      "First embedding value: [0.001451187883503735, -0.0232482198625803, -0.01903114840388298, -0.03325076773762703, 0.012469109147787094]\n",
      "\n",
      "‚ö†Ô∏è  Number of None embeddings: 0\n",
      "‚úÖ Number of valid embeddings: 25\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check what's in chunk_embeddings\n",
    "print(f\"Number of embeddings: {len(chunk_embeddings)}\")\n",
    "print(f\"First embedding type: {type(chunk_embeddings[0])}\")\n",
    "print(f\"First embedding value: {chunk_embeddings[1][:5]}\")\n",
    "\n",
    "# Count how many are None\n",
    "none_count = sum(1 for emb in chunk_embeddings if emb is None)\n",
    "print(f\"\\n‚ö†Ô∏è  Number of None embeddings: {none_count}\")\n",
    "\n",
    "# Check if any are valid\n",
    "valid_count = sum(1 for emb in chunk_embeddings if emb is not None and isinstance(emb, list))\n",
    "print(f\"‚úÖ Number of valid embeddings: {valid_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Initialize Qdrant Client (Cloud Mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to Qdrant\n"
     ]
    }
   ],
   "source": [
    "qdrant_client = QdrantClient(\n",
    "    url=qdrant_url,\n",
    "    api_key=qdrant_api_key\n",
    ")\n",
    "print(\"‚úÖ Connected to Qdrant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 1024\n",
      "Created collection 'qdrant_docs' with dimension 1024\n"
     ]
    }
   ],
   "source": [
    "# Collection name\n",
    "collection_name = \"qdrant_docs\"\n",
    "\n",
    "# Get embedding dimension\n",
    "embedding_dim = len(chunk_embeddings[0])\n",
    "print(f\"Embedding dimension: {embedding_dim}\")\n",
    "\n",
    "# Create collection\n",
    "qdrant_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=1024, distance=Distance.COSINE)\n",
    ")\n",
    "print(f\"Created collection '{collection_name}' with dimension {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 25 vectors to Qdrant\n",
      "Collection info: 25 points\n"
     ]
    }
   ],
   "source": [
    "# Prepare points for upload\n",
    "points = []\n",
    "for idx, (chunk, embedding) in enumerate(zip(chunks_sample, chunk_embeddings)):\n",
    "    point = PointStruct(\n",
    "        id=idx,\n",
    "        vector=embedding,\n",
    "        payload={\"text\": chunk, \"chunk_id\": idx}\n",
    "    )\n",
    "    points.append(point)\n",
    "\n",
    "# Upload to Qdrant\n",
    "qdrant_client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")\n",
    "\n",
    "print(f\"Uploaded {len(points)} vectors to Qdrant\")\n",
    "\n",
    "# Verify collection\n",
    "collection_info = qdrant_client.get_collection(collection_name)\n",
    "print(f\"Collection info: {collection_info.points_count} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Qdrant Collection Status\n",
    "\n",
    "**Collection initialized successfully!**\n",
    "\n",
    "- ‚úÖ Collection Name: `qdrant_docs`\n",
    "- ‚úÖ Vectors uploaded: 25 embeddings (1024 dimensions each)\n",
    "- ‚úÖ Verified in Qdrant Cloud UI\n",
    "\n",
    "The vector database is now ready for semantic search queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Define Retrieval Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fixed retrieval function defined!\n"
     ]
    }
   ],
   "source": [
    "# Fixed retrieval function with proper embedding format handling\n",
    "def retrieve_documents(query, top_k=3):\n",
    "    \"\"\"\n",
    "    Retrieve top_k most relevant documents for a query\n",
    "    \"\"\"\n",
    "    # Get query embedding from Replicate\n",
    "    query_embedding_result = get_embeddings_replicate([query])\n",
    "\n",
    "    # Extract the actual embedding (handle nested structure)\n",
    "    query_embedding = query_embedding_result[0]\n",
    "\n",
    "    # If it's still nested (double list), unwrap it\n",
    "    if isinstance(query_embedding, list) and len(query_embedding) > 0:\n",
    "        if isinstance(query_embedding[0], list):\n",
    "            # Double nested - take first element\n",
    "            query_embedding = query_embedding[0]\n",
    "\n",
    "    # Ensure it's a flat list of floats\n",
    "    if not isinstance(query_embedding, list):\n",
    "        raise ValueError(f\"Expected list, got {type(query_embedding)}\")\n",
    "\n",
    "    if len(query_embedding) == 0:\n",
    "        raise ValueError(\"Empty embedding vector\")\n",
    "\n",
    "    # Verify it contains numbers\n",
    "    if isinstance(query_embedding[0], list):\n",
    "        raise ValueError(\"Embedding is still nested! Check embedding generation.\")\n",
    "\n",
    "    # Search in Qdrant\n",
    "    search_results = qdrant_client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding,\n",
    "        limit=top_k\n",
    "    )\n",
    "\n",
    "    # Extract documents\n",
    "    retrieved_docs = []\n",
    "    for result in search_results:\n",
    "        retrieved_docs.append({\n",
    "            \"text\": result.payload[\"text\"],\n",
    "            \"score\": result.score,\n",
    "            \"chunk_id\": result.payload[\"chunk_id\"]\n",
    "        })\n",
    "\n",
    "    return retrieved_docs\n",
    "\n",
    "print(\"‚úÖ Fixed retrieval function defined!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Test Retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How does Qdrant handle hybrid search?\n",
      "\n",
      "Retrieving documents...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved documents:\n",
      "\n",
      "Document 1 (Score: 1.0000)\n",
      "Text: ---\n",
      "\n",
      "logos:\n",
      "\n",
      "  -  /img/customers-logo/flipkart.svg\n",
      "\n",
      "  -  /img/customers-logo/x.svg\n",
      "\n",
      "  -  /img/customers-logo/quora.svg\n",
      "\n",
      "sitemapExclude: true\n",
      "\n",
      "---...\n",
      "\n",
      "Document 2 (Score: 1.0000)\n",
      "Text: image:\n",
      "\n",
      "    src: /img/customers-case-studies/case-study.png\n",
      "\n",
      "    alt: Preview\n",
      "\n",
      "cases:\n",
      "\n",
      "- id: 0\n",
      "\n",
      "  logo:\n",
      "\n",
      "    src: /img/customers-case-studies/visua.svg\n",
      "\n",
      "    alt:  Visua Logo\n",
      "\n",
      "  image:\n",
      "\n",
      "    src: /img/customers-case-studies/case-visua.png\n",
      "\n",
      "    alt: The hands of a person in a medical gown holding a tablet against the background of a pharmacy shop\n",
      "\n",
      "  title: VISUA improves quality control process for computer vision with anomaly detection by 10x.\n",
      "\n",
      "  link:\n",
      "\n",
      "    text: Read Story\n",
      "\n",
      "    url: /blog/case-study-visua/\n",
      "\n",
      "- id: 1\n",
      "\n",
      "  logo:\n",
      "\n",
      "    src: /img/customers-case-studies/dust.svg\n",
      "\n",
      "    alt: Dust Logo\n",
      "\n",
      "  image:\n",
      "\n",
      "    src: /img/customers-case-studies/case-dust.png\n",
      "\n",
      "    alt: A man in a jeans shirt is holding a smartphone, only his hands are visible. In the foreground, there is an image of a robot surrounded by chat and sound waves.\n",
      "\n",
      "  title: Dust uses Qdrant for RAG, achieving millisecond retrieval, reducing costs by 50%, and boosting scalability.\n",
      "\n",
      "  link:\n",
      "\n",
      "    text: Read Story...\n",
      "\n",
      "Document 3 (Score: 1.0000)\n",
      "Text: - id: 9\n",
      "\n",
      "  name: Leonard P√ºttmann\n",
      "\n",
      "  position: data scientist\n",
      "\n",
      "  avatar:\n",
      "\n",
      "    src: /img/customers/leonard-puttmann.svg\n",
      "\n",
      "    alt: Avatar\n",
      "\n",
      "  text: Amidst the hype around vector databases, Qdrant is by far my favorite one. It's super fast (written in Rust) and open-source! At Kern AI we use Qdrant for fast document retrieval and to do quick similarity search for text data.\n",
      "\n",
      "- id: 10\n",
      "\n",
      "  name: Stanislas Polu\n",
      "\n",
      "  position: Software Engineer & Co-Founder, Dust\n",
      "\n",
      "  avatar:\n",
      "\n",
      "    src: /img/customers/stanislas-polu.svg\n",
      "\n",
      "    alt: Avatar\n",
      "\n",
      "  text: Qdrant's the best. By. Far.\n",
      "\n",
      "- id: 11\n",
      "\n",
      "  name: Sivesh Sukumar\n",
      "\n",
      "  position: Investor at Balderton\n",
      "\n",
      "  avatar:\n",
      "\n",
      "    src: /img/customers/sivesh-sukumar.svg\n",
      "\n",
      "    alt: Avatar\n",
      "\n",
      "  text: We're using Qdrant to help segment and source Europe's next wave of extraordinary companies!\n",
      "\n",
      "- id: 12\n",
      "\n",
      "  name: Saksham Gupta\n",
      "\n",
      "  position: AI Governance Machine Learning Engineer\n",
      "\n",
      "  avatar:\n",
      "\n",
      "    src: /img/customers/saksham-gupta.svg\n",
      "\n",
      "    alt: Avatar...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/y4/bcw5f3qd29sgfkhxkb5584000000gn/T/ipykernel_91814/1036155323.py:30: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_results = qdrant_client.search(\n"
     ]
    }
   ],
   "source": [
    "# Test query\n",
    "test_query = \"How does Qdrant handle hybrid search?\"\n",
    "\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "print(\"Retrieving documents...\\n\")\n",
    "\n",
    "retrieved_docs = retrieve_documents(test_query, top_k=3)\n",
    "\n",
    "print(\"Retrieved documents:\\n\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"Document {i} (Score: {doc['score']:.4f})\")\n",
    "    print(f\"Text: {doc['text']}...\\n\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Define LLM Function (OpenAI via Replicate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM function defined\n"
     ]
    }
   ],
   "source": [
    "# LLM generation function using OpenAI (Note: OpenAI isn't directly available on Replicate, using meta/llama instead)\n",
    "def generate_response(query, context_docs):\n",
    "    \"\"\"\n",
    "    Generate response using LLM via Replicate\n",
    "    \"\"\"\n",
    "    # Build context from retrieved documents\n",
    "    context = \"\\n\\n\".join([doc[\"text\"] for doc in context_docs])\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"You are a helpful assistant. Use the following context to answer the question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer: Provide a comprehensive answer based on the context above. If the context doesn't contain enough information, say so.\"\"\"\n",
    "\n",
    "    # Generate response using Replicate (using Llama as OpenAI not available on Replicate directly)\n",
    "    try:\n",
    "        output = replicate.run(\n",
    "            \"openai/gpt-5-nano\",\n",
    "            input={\n",
    "                \"prompt\": prompt,\n",
    "                \"max_tokens\": 500,\n",
    "                \"temperature\": 0.7\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Concatenate output if it's a generator\n",
    "        if hasattr(output, '__iter__') and not isinstance(output, str):\n",
    "            response = \"\".join(output)\n",
    "        else:\n",
    "            response = output\n",
    "\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        return \"Error: Could not generate response\"\n",
    "\n",
    "print(\"LLM function defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 15: Complete RAG Pipeline Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is Qdrant and how does it handle vector search?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Step 1: Retrieving relevant documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.04it/s]\n",
      "/var/folders/y4/bcw5f3qd29sgfkhxkb5584000000gn/T/ipykernel_91814/1036155323.py:30: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_results = qdrant_client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 documents\n",
      "\n",
      "Step 2: Generating response...\n",
      "\n",
      "================================================================================\n",
      "RESPONSE:\n",
      "================================================================================\n",
      "Based on the provided context, there isn‚Äôt a direct, explicit definition of what Qdrant is or how it handles vector search. However, there are surrounding hints from user testimonials and case studies that imply its role and capabilities:\n",
      "\n",
      "- Several customers reference Qdrant in the context of fast document retrieval and similarity search:\n",
      "  - Leonard P√ºttmann (data scientist) says: ‚ÄúAmidst the hype around vector databases, Qdrant is by far my favorite one. It‚Äôs super fast (written in Rust) and open-source! At Kern AI we use Qdrant for fast document retrieval and to do quick similarity search for text data.‚Äù\n",
      "  - Stanislas Polu (Dust) states: ‚ÄúQdrant's the best. By. Far.‚Äù\n",
      "  - A Dust case study mentions: ‚ÄúDust uses Qdrant for RAG, achieving millisecond retrieval, reducing costs by 50%, and boosting scalability.‚Äù\n",
      "\n",
      "From these, we can infer the following about Qdrant (as a product category and its typical use in vector search contexts):\n",
      "\n",
      "- Qdrant is a vector database designed for vector search and retrieval tasks.\n",
      "- It is employed for fast document retrieval and similarity search, indicating support for high-performance nearest-neighbor search on high-dimensional vectors.\n",
      "- It is described as fast (noting it is written in Rust) and open-source.\n",
      "- It is suitable for use cases like retrieval-augmented generation (RAG), enabling millisecond retrieval times, and can help reduce costs and improve scalability in such workflows.\n",
      "\n",
      "If you need a formal, stand-alone definition beyond these implications, the provided context does not include a canonical description of Qdrant. Based on the context, the best summary is:\n",
      "\n",
      "- Qdrant is an open-source vector database optimized for fast vector search and retrieval, used to perform efficient similarity searches and support retrieval-augmented workflows, with emphasis on speed (millisecond-level retrieval) and scalability.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Complete RAG pipeline\n",
    "query = \"What is Qdrant and how does it handle vector search?\"\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Step 1: Retrieve\n",
    "print(\"\\nStep 1: Retrieving relevant documents...\")\n",
    "retrieved_docs = retrieve_documents(query, top_k=3)\n",
    "print(f\"Retrieved {len(retrieved_docs)} documents\")\n",
    "\n",
    "# Step 2: Generate\n",
    "print(\"\\nStep 2: Generating response...\")\n",
    "response = generate_response(query, retrieved_docs)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESPONSE:\")\n",
    "print(\"=\" * 80)\n",
    "print(response)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SOURCES:\n",
      "================================================================================\n",
      "\n",
      "Source 1 (Relevance: 1.0000):\n",
      "---\n",
      "\n",
      "logos:\n",
      "\n",
      "  -  /img/customers-logo/flipkart.svg\n",
      "\n",
      "  -  /img/customers-logo/x.svg\n",
      "\n",
      "  -  /img/customers-logo/quora.svg\n",
      "\n",
      "sitemapExclude: true\n",
      "\n",
      "---...\n",
      "\n",
      "Source 2 (Relevance: 1.0000):\n",
      "image:\n",
      "\n",
      "    src: /img/customers-case-studies/case-study.png\n",
      "\n",
      "    alt: Preview\n",
      "\n",
      "cases:\n",
      "\n",
      "- id: 0\n",
      "\n",
      "  logo:\n",
      "\n",
      "    src: /img/customers-case-studies/visua.svg\n",
      "\n",
      "    alt:  Visua Logo\n",
      "\n",
      "  image:\n",
      "\n",
      "    src: /img/customers-case-studies/case-visua.png\n",
      "\n",
      "    alt: The hands of a person in a medical gown holding a tab...\n",
      "\n",
      "Source 3 (Relevance: 1.0000):\n",
      "- id: 9\n",
      "\n",
      "  name: Leonard P√ºttmann\n",
      "\n",
      "  position: data scientist\n",
      "\n",
      "  avatar:\n",
      "\n",
      "    src: /img/customers/leonard-puttmann.svg\n",
      "\n",
      "    alt: Avatar\n",
      "\n",
      "  text: Amidst the hype around vector databases, Qdrant is by far my favorite one. It's super fast (written in Rust) and open-source! At Kern AI we use Qdrant for ...\n"
     ]
    }
   ],
   "source": [
    "# Display sources\n",
    "print(\"\\nSOURCES:\")\n",
    "print(\"=\" * 80)\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"\\nSource {i} (Relevance: {doc['score']:.4f}):\")\n",
    "    print(doc['text'][:300] + \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps to do\n",
    "\n",
    "1. Try loading the entire dataset. \n",
    "2. Check the chunks in the other notebook from the workshops.\n",
    "3. Run it against the eval section to see if it's still failing \n",
    "4. Investigate why the matches are always 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mimic_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
